{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import csv\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from scipy.misc import imread\n",
    "from scipy.misc import imsave\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.slim.nets import inception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "slim = tf.contrib.slim\n",
    "\n",
    "\n",
    "tf.flags.DEFINE_string(\n",
    "    'master', '', 'The address of the TensorFlow master to use.')\n",
    "\n",
    "tf.flags.DEFINE_string(\n",
    "    'checkpoint_path', '', '../input/inception-v3/inception_v3.ckpt')\n",
    "\n",
    "tf.flags.DEFINE_string(\n",
    "    'input_dir', '', '../input/images')\n",
    "\n",
    "tf.flags.DEFINE_string(\n",
    "    'output_dir', '', '../input')\n",
    "\n",
    "tf.flags.DEFINE_float(\n",
    "    'max_epsilon', 16.0, 'Maximum size of adversarial perturbation.')\n",
    "\n",
    "tf.flags.DEFINE_integer(\n",
    "    'image_width', 299, 'Width of each input images.')\n",
    "\n",
    "tf.flags.DEFINE_integer(\n",
    "    'image_height', 299, 'Height of each input images.')\n",
    "\n",
    "tf.flags.DEFINE_integer(\n",
    "    'num_channels', 3, 'How many images process at one time.')\n",
    "\n",
    "tf.flags.DEFINE_integer(\n",
    "    'batch_size', 16, 'How many images process at one time.')\n",
    "\n",
    "tf.flags.DEFINE_float(\n",
    "    'noise_limit', 0.35, 'Maximum size of adversarial perturbation.')\n",
    "\n",
    "tf.flags.DEFINE_float(\n",
    "    'noise_l2_weight', 0.02, 'Maximum size of adversarial perturbation.')\n",
    "tf.flags.DEFINE_integer(\n",
    "    'num_classes', 1001, 'How many images process at one time.')  \n",
    "\n",
    "\n",
    "FLAGS = tf.flags.FLAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_target_class(input_dir):\n",
    "    with tf.gfile.Open(os.path.join(input_dir, '../input/images.csv')) as f:\n",
    "        next(f) # skip header\n",
    "        return {row[0]+\".png\": int(row[6]) for row in csv.reader(f) if len(row) >= 7}\n",
    "\n",
    "def save_images(images, filenames, output_dir):\n",
    "    for i, filename in enumerate(filenames):\n",
    "        with tf.gfile.Open(os.path.join(output_dir, filename), 'wb') as f:\n",
    "            imsave(f, (images[i, :, :, :] + 1.0) * 0.5, format='png')\n",
    "\n",
    "def load_images(input_dir, batch_shape):\n",
    "    images = np.zeros(batch_shape)\n",
    "    filenames = []\n",
    "    idx = 0\n",
    "    batch_size = batch_shape[0]\n",
    "    # Limit to first 20 images for this example\n",
    "    for filepath in tf.gfile.Glob(os.path.join(input_dir, '*.png'))[:20]:\n",
    "        with tf.gfile.Open(filepath, \"rb\") as f:\n",
    "            images[idx, :, :, :] = imread(f, mode='RGB').astype(np.float) / 255.0\n",
    "        filenames.append(os.path.basename(filepath))\n",
    "        idx += 1\n",
    "        if idx == batch_size:\n",
    "            yield filenames, images\n",
    "            filenames = []\n",
    "            images = np.zeros(batch_shape)\n",
    "            idx = 0\n",
    "    if idx > 0:\n",
    "        yield filenames, images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ADVERSARY_VARIABLES = 'adversary_variables'\n",
    "collections = [tf.GraphKeys.VARIABLES, ADVERSARY_VARIABLES]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def main(_):\n",
    "  \n",
    "      eps = 2.0 * FLAGS.max_epsilon / 255.0\n",
    "      batch_shape = [FLAGS.batch_size, FLAGS.image_height, FLAGS.image_width, 3]\n",
    "      y_true = tf.placeholder(tf.float32, shape=[None, FLAGS.num_classes], name='y_true')\n",
    "      \n",
    "      num_classes = 1001\n",
    "\n",
    "      tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "      all_images_taget_class = load_target_class(FLAGS.input_dir)\n",
    "        \n",
    "      img_size_flat = FLAGS.image_height * FLAGS.image_width\n",
    "     \n",
    "     \n",
    "      x_image = tf.placeholder(tf.float32, shape=batch_shape,name='x_image')\n",
    "\n",
    "      with tf.Graph().as_default():\n",
    "        # Prepare graph\n",
    "        x_input = tf.placeholder(tf.float32, shape=batch_shape)\n",
    "\n",
    "        with slim.arg_scope(inception.inception_v3_arg_scope()):\n",
    "            logits, end_points = inception.inception_v3(\n",
    "              x_input, num_classes=num_classes, is_training=False)\n",
    "\n",
    "            target_class_input = tf.placeholder(tf.int32, shape=[FLAGS.batch_size])\n",
    "            \n",
    "            one_hot_target_class = tf.one_hot(target_class_input, num_classes)\n",
    "          \n",
    "        \n",
    "            #x_noise = tf.Variable(tf.zeros_like(x_image),\n",
    "                      #name='x_noise', trainable=False,\n",
    "                      #collections=collections)\n",
    "          \n",
    "            \n",
    "            #x_noise_clip = tf.assign(x_noise, tf.clip_by_value(x_noise,\n",
    "                                                 #  -FLAGS.noise_limit,\n",
    "                                                  # FLAGS.noise_limit))\n",
    "           # x_noisy_image = x_image + x_noise\n",
    "            #x_noisy_image = tf.clip_by_value(x_noisy_image, 0.0, 1.0)\n",
    "            \n",
    "           \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            y_pred_cls = tf.argmax(logits, dimension=1)\n",
    "            y_true_cls = tf.argmax(logits, dimension=1)\n",
    "            correct_prediction = tf.equal(y_pred_cls, y_true_cls)\n",
    "            accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "            \n",
    "            loss = tf.losses.softmax_cross_entropy(one_hot_target_class,\n",
    "                                                    logits,\n",
    "                                                    label_smoothing=0.1,\n",
    "                                                    weights=1.0)\n",
    "            loss += tf.losses.softmax_cross_entropy(one_hot_target_class,\n",
    "                                                     end_points['AuxLogits'],\n",
    "                                                     label_smoothing=0.1,\n",
    "                                                     weights=0.4)\n",
    "            #l2_loss_noise = FLAGS.noise_l2_weight * tf.nn.l2_loss(x_noisy_image)\n",
    "            x_adv = x_input - eps * tf.sign(tf.gradients(loss, x_input)[0])\n",
    "            x_adv = tf.clip_by_value(x_adv, -1.0, 1.0)\n",
    "            loss_adversary = tf.add(loss , x_adv)\n",
    "            \n",
    "            #adversary_variables = tf.get_collection(ADVERSARY_VARIABLES)\n",
    "            #optimizer = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(loss)\n",
    "            #optimizer_adversary = tf.train.AdamOptimizer(learning_rate=1e-2).minimize(x_adv)\n",
    "            \n",
    "            \n",
    "            #x_adv = x_input - eps * tf.sign(tf.gradients(loss, x_input)[0])\n",
    "            #\n",
    "\n",
    "            # Run computation\n",
    "            saver = tf.train.Saver(slim.get_model_variables())\n",
    "            session_creator = tf.train.ChiefSessionCreator(\n",
    "            scaffold=tf.train.Scaffold(saver=saver),\n",
    "            checkpoint_filename_with_path=FLAGS.checkpoint_path,\n",
    "            master=FLAGS.master)\n",
    "\n",
    "        with tf.train.MonitoredSession(session_creator=session_creator) as sess:\n",
    "              for filenames, images in load_images(FLAGS.input_dir, batch_shape):\n",
    "                target_class_for_batch = (\n",
    "                [all_images_taget_class[n] for n in filenames]\n",
    "                + [0] * (FLAGS.batch_size - len(filenames)))\n",
    "                \n",
    "                #sess.run(tf.global_variables_initializer())\n",
    "                #sess.run(tf.variables_initializer([x_noise]))\n",
    "                adv_images = sess.run(x_adv,\n",
    "                              feed_dict={\n",
    "                                  x_input: images,\n",
    "                                  target_class_input: target_class_for_batch\n",
    "                              })\n",
    "                #sess.run(x_noise_clip)\n",
    "                save_images(adv_images, filenames, FLAGS.output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "      tf.app.run()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
