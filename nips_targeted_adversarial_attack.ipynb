{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import csv\n",
    "from cleverhans.attacks import FastGradientMethod\n",
    "from io import BytesIO\n",
    "import IPython.display\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from scipy.misc import imread\n",
    "from scipy.misc import imsave\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.slim.nets import inception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "slim = tf.contrib.slim\n",
    "\n",
    "\n",
    "tf.flags.DEFINE_string(\n",
    "    'master', '', 'The address of the TensorFlow master to use.')\n",
    "\n",
    "tf.flags.DEFINE_string(\n",
    "    'checkpoint_path', '', '../input/inception-v3/inception_v3.ckpt')\n",
    "\n",
    "tf.flags.DEFINE_string(\n",
    "    'input_dir', '', '../input/images')\n",
    "\n",
    "tf.flags.DEFINE_string(\n",
    "    'output_dir', '', '../input')\n",
    "\n",
    "tf.flags.DEFINE_float(\n",
    "    'max_epsilon', 16.0, 'Maximum size of adversarial perturbation.')\n",
    "\n",
    "tf.flags.DEFINE_integer(\n",
    "    'image_width', 299, 'Width of each input images.')\n",
    "\n",
    "tf.flags.DEFINE_integer(\n",
    "    'image_height', 299, 'Height of each input images.')\n",
    "\n",
    "tf.flags.DEFINE_integer(\n",
    "    'num_channels', 3, 'How many images process at one time.')\n",
    "\n",
    "tf.flags.DEFINE_integer(\n",
    "    'batch_size', 16, 'How many images process at one time.')\n",
    "\n",
    "tf.flags.DEFINE_float(\n",
    "    'noise_limit', 0.35, 'Maximum size of adversarial perturbation.')\n",
    "\n",
    "tf.flags.DEFINE_float(\n",
    "    'noise_l2_weight', 0.02, 'Maximum size of adversarial perturbation.')\n",
    "tf.flags.DEFINE_integer(\n",
    "    'num_classes', 1001, 'How many images process at one time.')  \n",
    "\n",
    "\n",
    "FLAGS = tf.flags.FLAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_shape = [FLAGS.batch_size, FLAGS.image_height, FLAGS.image_width, 3]\n",
    "resized_image = [1,288,288,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_target_class(input_dir):\n",
    "    with tf.gfile.Open(os.path.join(input_dir, './input/images.csv')) as f:\n",
    "        next(f) # skip header\n",
    "        return {row[0]+\".png\": int(row[6]) for row in csv.reader(f) if len(row) >= 7}\n",
    "\n",
    "def save_images(images, filenames, output_dir):\n",
    "    for i, filename in enumerate(filenames):\n",
    "        with tf.gfile.Open(os.path.join(output_dir, filename), 'wb') as f:\n",
    "            imsave(f, (images[i, :, :, :] + 1.0) * 0.5, format='png')\n",
    "\n",
    "def load_images(input_dir, batch_shape):\n",
    "    images = np.zeros(batch_shape)\n",
    "    filenames = []\n",
    "    idx = 0\n",
    "    batch_size = batch_shape[0]\n",
    "    for filepath in sorted(tf.gfile.Glob(os.path.join(input_dir, '*.png'))):\n",
    "        with tf.gfile.Open(filepath, \"rb\") as f:\n",
    "            images[idx, :, :, :] = imread(f, mode='RGB').astype(np.float)*2.0/255.0 - 1.0\n",
    "        filenames.append(os.path.basename(filepath))\n",
    "        idx += 1\n",
    "        if idx == batch_size:\n",
    "            yield filenames, images\n",
    "            filenames = []\n",
    "            images = np.zeros(batch_shape)\n",
    "            idx = 0\n",
    "    if idx > 0:\n",
    "        yield filenames, images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    " with tf.Graph().as_default():\n",
    "    # Add a placeholder variable for the target class-number.\n",
    "    # This will be set to e.g. 300 for the 'bookcase' class.\n",
    "    x_input = tf.placeholder(tf.float32, shape=batch_shape)\n",
    "\n",
    "    with slim.arg_scope(inception.inception_v3_arg_scope()):\n",
    "        y_logits, end_points = inception.inception_v3(\n",
    "              x_input, num_classes=FLAGS.num_classes, is_training=False)\n",
    "\n",
    "        target_class_input = tf.placeholder(tf.int32, shape=[FLAGS.batch_size])\n",
    "            \n",
    "        one_hot_target_class = tf.one_hot(target_class_input, FLAGS.num_classes)\n",
    "        pl_cls_target = tf.placeholder(dtype=tf.int32)\n",
    "\n",
    "        # Add a new loss-function. This is the cross-entropy.\n",
    "        # See Tutorial #01 for an explanation of cross-entropy.\n",
    "        loss = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=y_logits, labels=[pl_cls_target])\n",
    "\n",
    "        # Get the gradient for the loss-function with regard to\n",
    "        # the resized input image.\n",
    "        gradient = tf.gradients(loss, resized_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "  eps = 2.0 * FLAGS.max_epsilon / 255.0\n",
    "  alpha = 2.0 * FLAGS.iter_alpha / 255.0\n",
    "  num_iter = FLAGS.num_iter\n",
    "  batch_shape = [FLAGS.batch_size, FLAGS.image_height, FLAGS.image_width, 3]\n",
    "  num_classes = 1001\n",
    "\n",
    "  tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "  all_images_taget_class = load_target_class(FLAGS.input_dir)\n",
    "\n",
    "  with tf.Graph().as_default():\n",
    "    # Prepare graph\n",
    "    x_input = tf.placeholder(tf.float32, shape=batch_shape)\n",
    "    x_max = tf.clip_by_value(x_input + eps, -1.0, 1.0)\n",
    "    x_min = tf.clip_by_value(x_input - eps, -1.0, 1.0)\n",
    "\n",
    "    with slim.arg_scope(inception.inception_v3_arg_scope()):\n",
    "      inception.inception_v3(\n",
    "          x_input, num_classes=num_classes, is_training=False)\n",
    "\n",
    "    x_adv = x_input\n",
    "    target_class_input = tf.placeholder(tf.int32, shape=[FLAGS.batch_size])\n",
    "    one_hot_target_class = tf.one_hot(target_class_input, num_classes)\n",
    "\n",
    "    for _ in range(num_iter):\n",
    "      with slim.arg_scope(inception.inception_v3_arg_scope()):\n",
    "        logits, end_points = inception.inception_v3(\n",
    "            x_adv, num_classes=num_classes, is_training=False, reuse=True)\n",
    "      cross_entropy = tf.losses.softmax_cross_entropy(one_hot_target_class,\n",
    "                                                      logits,\n",
    "                                                      label_smoothing=0.1,\n",
    "                                                      weights=1.0)\n",
    "      cross_entropy += tf.losses.softmax_cross_entropy(one_hot_target_class,\n",
    "                                                       end_points['AuxLogits'],\n",
    "                                                       label_smoothing=0.1,\n",
    "                                                       weights=0.4)\n",
    "      x_next = x_adv - alpha * tf.sign(tf.gradients(cross_entropy, x_adv)[0])\n",
    "      x_next = tf.clip_by_value(x_next, x_min, x_max)\n",
    "      x_adv = x_next\n",
    "\n",
    "    # Run computation\n",
    "    saver = tf.train.Saver(slim.get_model_variables())\n",
    "    session_creator = tf.train.ChiefSessionCreator(\n",
    "        scaffold=tf.train.Scaffold(saver=saver),\n",
    "        checkpoint_filename_with_path=FLAGS.checkpoint_path,\n",
    "        master=FLAGS.master)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_image(x):\n",
    "    # Get the min and max values for all pixels in the input.\n",
    "    x_min = x.min()\n",
    "    x_max = x.max()\n",
    "\n",
    "    # Normalize so all values are between 0.0 and 1.0\n",
    "    x_norm = (x - x_min) / (x_max - x_min)\n",
    "\n",
    "    return x_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def adversary_noise(image_path, cls_target, noise_limit=3.0,\n",
    "                         required_score=0.99, max_iterations=100):\n",
    "    \n",
    "\n",
    "    # Create a feed-dict with the image.\n",
    "    \n",
    "    feed_dict = model._create_feed_dict(image_path=image_path)\n",
    "   \n",
    " \n",
    "\n",
    "    # Use TensorFlow to calculate the predicted class-scores\n",
    "    # (aka. probabilities) as well as the resized image.\n",
    "    pred, image = session.run([y_pred, resized_image],\n",
    "                              feed_dict=feed_dict)\n",
    "\n",
    "    # Convert to one-dimensional array.\n",
    "    pred = np.squeeze(pred)\n",
    "\n",
    "    # Predicted class-number.\n",
    "    cls_source = np.argmax(pred)\n",
    "\n",
    "    # Score for the predicted class (aka. probability or confidence).\n",
    "    score_source_org = pred.max()\n",
    "\n",
    "    # Names for the source and target classes.\n",
    "    name_source = model.name_lookup.cls_to_name(cls_source,\n",
    "                                                only_first_name=True)\n",
    "    name_target = model.name_lookup.cls_to_name(cls_target,\n",
    "                                                only_first_name=True)\n",
    "\n",
    "    # Initialize the noise to zero.\n",
    "    noise = 0\n",
    "\n",
    "    # Perform a number of optimization iterations to find\n",
    "    # the noise that causes mis-classification of the input image.\n",
    "    for i in range(max_iterations):\n",
    "        print(\"Iteration:\", i)\n",
    "\n",
    "        # The noisy image is just the sum of the input image and noise.\n",
    "        noisy_image = image + noise\n",
    "\n",
    "        \n",
    "        noisy_image = np.clip(a=noisy_image, a_min=0.0, a_max=255.0)\n",
    "\n",
    "        feed_dict = {model.tensor_name_resized_image: noisy_image,\n",
    "                     pl_cls_target: cls_target}\n",
    "\n",
    "        # Calculate the predicted class-scores as well as the gradient.\n",
    "        pred, grad = session.run([y_pred, gradient],\n",
    "                                 feed_dict=feed_dict)\n",
    "\n",
    "        # Convert the predicted class-scores to a one-dim array.\n",
    "        pred = np.squeeze(pred)\n",
    "\n",
    "        # The scores (probabilities) for the source and target classes.\n",
    "        score_source = pred[cls_source]\n",
    "        score_target = pred[cls_target]\n",
    "\n",
    "        # Squeeze the dimensionality for the gradient-array.\n",
    "        grad = np.array(grad).squeeze()\n",
    "\n",
    "        \n",
    "        grad_absmax = np.abs(grad).max()\n",
    "        \n",
    "        # If the gradient is very small then use a lower limit,\n",
    "        # because we will use it as a divisor.\n",
    "        if grad_absmax < 1e-10:\n",
    "            grad_absmax = 1e-10\n",
    "\n",
    "        step_size = 7 / grad_absmax\n",
    "\n",
    "        \n",
    "\n",
    "        # If the score for the target-class is not high enough.\n",
    "        if score_target < required_score:\n",
    "            # Update the image-noise by subtracting the gradient\n",
    "            # scaled by the step-size.\n",
    "            noise -= step_size * grad\n",
    "\n",
    "            # Ensure the noise is within the desired range.\n",
    "            # This avoids distorting the image too much.\n",
    "            noise = np.clip(a=noise,\n",
    "                            a_min=-noise_limit,\n",
    "                            a_max=noise_limit)\n",
    "        else:\n",
    "            # Abort the optimization because the score is high enough.\n",
    "            break\n",
    "\n",
    "    return image.squeeze(), noisy_image.squeeze(), noise, \\\n",
    "           name_source, name_target, \\\n",
    "           score_source, score_source_org, score_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def target_attack(image_path, cls_target,\n",
    "                      noise_limit, required_score):\n",
    "   \n",
    "\n",
    "    # Find the adversarial noise.\n",
    "    image, noisy_image, noise, \\\n",
    "    name_source, name_target, \\\n",
    "    score_source, score_source_org, score_target = \\\n",
    "        adversary_noise(image_path=image_path,\n",
    "                             cls_target=cls_target,\n",
    "                             noise_limit=noise_limit,\n",
    "                             required_score=required_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    with tf.train.MonitoredSession(session_creator=session_creator) as sess:\n",
    "          for filenames, images in load_images(FLAGS.input_dir, batch_shape):\n",
    "            target_class_for_batch = (\n",
    "            [all_images_taget_class[n] for n in filenames]\n",
    "            + [0] * (FLAGS.batch_size - len(filenames)))\n",
    "\n",
    "            #sess.run(tf.global_variables_initializer())\n",
    "            #sess.run(tf.variables_initializer([x_noise]))\n",
    "            adv_images = sess.run(target_attack(image_path, cls_target,\n",
    "                      noise_limit, required_score))\n",
    "            #sess.run(x_noise_clip)\n",
    "            save_images(adv_images, filenames, FLAGS.output_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
